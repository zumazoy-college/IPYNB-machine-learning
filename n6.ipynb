{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "865ea878",
   "metadata": {},
   "source": [
    "<center><h1>Практическая работа №6</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134204e5",
   "metadata": {},
   "source": [
    "<center><h2>Тема работы: \"Кластеризация\"</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6782c5f",
   "metadata": {},
   "source": [
    "<h5>Цель работы: провести кластеризацию данных автомобилей из датасета cardekho.csv, используя различные алгоритмы, оценить их качество метриками и сравнить результаты до и после понижения размерности.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b277fb",
   "metadata": {},
   "source": [
    "<h5>Ход работы:</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b26ee7",
   "metadata": {},
   "source": [
    "<h4>1. Загрузка данных и первичный анализ.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6538ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # библиотека для работы с табличными данными\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler # инструмент для масштабирования данных (приведение к единому масштабу)\n",
    "from sklearn.decomposition import PCA # метод понижения размерности (Principal Component Analysis)\n",
    "from sklearn.cluster import KMeans, DBSCAN # алгоритмы кластеризации\n",
    "from sklearn.mixture import GaussianMixture # алгоритмы кластеризации\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score # метрики для оценки качества кластеризации\n",
    "\n",
    "from IPython.display import Markdown, display # для красивого отображения таблиц в Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90ff1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 8128 entries, 0 to 8127\n",
      "Data columns (total 12 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   name                8128 non-null   str    \n",
      " 1   year                8128 non-null   int64  \n",
      " 2   selling_price       8128 non-null   int64  \n",
      " 3   km_driven           8128 non-null   int64  \n",
      " 4   fuel                8128 non-null   str    \n",
      " 5   seller_type         8128 non-null   str    \n",
      " 6   transmission        8128 non-null   str    \n",
      " 7   owner               8128 non-null   str    \n",
      " 8   mileage(km/ltr/kg)  7907 non-null   float64\n",
      " 9   engine              7907 non-null   float64\n",
      " 10  max_power           7913 non-null   str    \n",
      " 11  seats               7907 non-null   float64\n",
      "dtypes: float64(3), int64(3), str(6)\n",
      "memory usage: 762.1 KB\n"
     ]
    }
   ],
   "source": [
    "path = r\"A:\\\\Programs\\\\M_VS_Code_projects\\\\jupyter\\\\IPYNB-machine-learning\\\\cardekho.csv\"\n",
    "df = pd.read_csv(path) # загружает данные из CSV-файла в DataFrame pandas\n",
    "df.info() # выводит сводную информацию о DataFrame: структуру, типы данных и количество ненулевых значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a889e6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер данных после очистки: (7906, 7)\n",
      "\n",
      "Статистика очищенных данных:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>mileage(km/ltr/kg)</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7906.000000</td>\n",
       "      <td>7.906000e+03</td>\n",
       "      <td>7.906000e+03</td>\n",
       "      <td>7906.000000</td>\n",
       "      <td>7906.000000</td>\n",
       "      <td>7906.000000</td>\n",
       "      <td>7906.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2013.983936</td>\n",
       "      <td>6.498137e+05</td>\n",
       "      <td>6.918866e+04</td>\n",
       "      <td>19.419861</td>\n",
       "      <td>1458.708829</td>\n",
       "      <td>91.587374</td>\n",
       "      <td>5.416393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.863695</td>\n",
       "      <td>8.135827e+05</td>\n",
       "      <td>5.679230e+04</td>\n",
       "      <td>4.036263</td>\n",
       "      <td>503.893057</td>\n",
       "      <td>35.747216</td>\n",
       "      <td>0.959208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>2.999900e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>624.000000</td>\n",
       "      <td>32.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2012.000000</td>\n",
       "      <td>2.700000e+05</td>\n",
       "      <td>3.500000e+04</td>\n",
       "      <td>16.780000</td>\n",
       "      <td>1197.000000</td>\n",
       "      <td>68.050000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>6.000000e+04</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>1248.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>6.900000e+05</td>\n",
       "      <td>9.542500e+04</td>\n",
       "      <td>22.320000</td>\n",
       "      <td>1582.000000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "      <td>2.360457e+06</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>3604.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              year  selling_price     km_driven  mileage(km/ltr/kg)  \\\n",
       "count  7906.000000   7.906000e+03  7.906000e+03         7906.000000   \n",
       "mean   2013.983936   6.498137e+05  6.918866e+04           19.419861   \n",
       "std       3.863695   8.135827e+05  5.679230e+04            4.036263   \n",
       "min    1994.000000   2.999900e+04  1.000000e+00            0.000000   \n",
       "25%    2012.000000   2.700000e+05  3.500000e+04           16.780000   \n",
       "50%    2015.000000   4.500000e+05  6.000000e+04           19.300000   \n",
       "75%    2017.000000   6.900000e+05  9.542500e+04           22.320000   \n",
       "max    2020.000000   1.000000e+07  2.360457e+06           42.000000   \n",
       "\n",
       "            engine    max_power        seats  \n",
       "count  7906.000000  7906.000000  7906.000000  \n",
       "mean   1458.708829    91.587374     5.416393  \n",
       "std     503.893057    35.747216     0.959208  \n",
       "min     624.000000    32.800000     2.000000  \n",
       "25%    1197.000000    68.050000     5.000000  \n",
       "50%    1248.000000    82.000000     5.000000  \n",
       "75%    1582.000000   102.000000     5.000000  \n",
       "max    3604.000000   400.000000    14.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Выбор числовых признаков и очистка\n",
    "df['max_power'] = pd.to_numeric(df['max_power'], errors='coerce') # пытается преобразовать столбец в числовой формат\n",
    "# errors='coerce' — преобразует значения в числа, а если встречается текст (например, \"null\", \"bhp\"), заменяет их на NaN\n",
    "\n",
    "# Выбираем только числовые столбцы, которые могут быть полезны\n",
    "numeric_features = ['year', 'selling_price', 'km_driven', 'mileage(km/ltr/kg)', 'engine', 'max_power', 'seats']\n",
    "df_numeric = df[numeric_features].copy()\n",
    "\n",
    "# Удаляем строки с пропущенными значениями (NaN)\n",
    "df_clean = df_numeric.dropna()\n",
    "\n",
    "print(\"Размер данных после очистки:\", df_clean.shape) # .shape — возвращает кортеж (количество строк, количество столбцов)\n",
    "print(\"\\nСтатистика очищенных данных:\")\n",
    "df_clean.describe() # describe() — выводит среднее, минимум, максимум и квантили для чисел"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d021b",
   "metadata": {},
   "source": [
    "<h5>Масштабирование данных</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12e88ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Масштабированные данные (первые 5 строк):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>selling_price</th>\n",
       "      <th>km_driven</th>\n",
       "      <th>mileage(km/ltr/kg)</th>\n",
       "      <th>engine</th>\n",
       "      <th>max_power</th>\n",
       "      <th>seats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>-0.245613</td>\n",
       "      <td>1.343777</td>\n",
       "      <td>0.986157</td>\n",
       "      <td>-0.418188</td>\n",
       "      <td>-0.492024</td>\n",
       "      <td>-0.434128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004158</td>\n",
       "      <td>-0.343950</td>\n",
       "      <td>0.894744</td>\n",
       "      <td>0.426198</td>\n",
       "      <td>0.077980</td>\n",
       "      <td>0.333827</td>\n",
       "      <td>-0.434128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.066530</td>\n",
       "      <td>-0.604542</td>\n",
       "      <td>1.246926</td>\n",
       "      <td>-0.426129</td>\n",
       "      <td>0.075995</td>\n",
       "      <td>-0.380120</td>\n",
       "      <td>-0.434128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.031186</td>\n",
       "      <td>-0.522185</td>\n",
       "      <td>1.018008</td>\n",
       "      <td>0.887050</td>\n",
       "      <td>-0.124457</td>\n",
       "      <td>-0.044408</td>\n",
       "      <td>-0.434128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.807694</td>\n",
       "      <td>-0.638960</td>\n",
       "      <td>0.894744</td>\n",
       "      <td>-0.822561</td>\n",
       "      <td>-0.318955</td>\n",
       "      <td>-0.094765</td>\n",
       "      <td>-0.434128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  selling_price  km_driven  mileage(km/ltr/kg)    engine  \\\n",
       "0  0.004158      -0.245613   1.343777            0.986157 -0.418188   \n",
       "1  0.004158      -0.343950   0.894744            0.426198  0.077980   \n",
       "2 -2.066530      -0.604542   1.246926           -0.426129  0.075995   \n",
       "3 -1.031186      -0.522185   1.018008            0.887050 -0.124457   \n",
       "4 -1.807694      -0.638960   0.894744           -0.822561 -0.318955   \n",
       "\n",
       "   max_power     seats  \n",
       "0  -0.492024 -0.434128  \n",
       "1   0.333827 -0.434128  \n",
       "2  -0.380120 -0.434128  \n",
       "3  -0.044408 -0.434128  \n",
       "4  -0.094765 -0.434128  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler() # создает объект для стандартизации данных (приведения к среднему 0 и стандартному отклонению 1)\n",
    "X_scaled = scaler.fit_transform(df_clean) # сначала вычисляет параметры масштабирования (среднее и стандартное отклонение), затем применяет преобразование к данным\n",
    "\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=numeric_features)\n",
    "print(\"Масштабированные данные (первые 5 строк):\")\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9e18a2",
   "metadata": {},
   "source": [
    "<h4>2. Кластеризация на исходных масштабированных данных.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf26e90d",
   "metadata": {},
   "source": [
    "<h5>\n",
    "Silhouette Score: Измеряет, насколько объект похож на свой кластер по сравнению с другими. Чем ближе к 1, тем лучше.</br>\n",
    "\n",
    "Davies-Bouldin Score: Измеряет среднее \"сходство\" между кластерами. Чем ниже значение, тем лучше разделение кластеров.\n",
    "\n",
    "Calinski-Harabasz Score: Оценивает, насколько кластеры плотные и хорошо разделенные. Чем выше значение, тем лучше.\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37ca5d",
   "metadata": {},
   "source": [
    "<h5>\n",
    "K-Means — это один из самых простых и популярных алгоритмов кластеризации. Он разделяет данные на заданное количество групп (кластеров) K.<br>\n",
    "Как работает:\n",
    "<ol>\n",
    "<li>Алгоритм случайным образом выбирает K точек в качестве центров кластеров</li>\n",
    "<li>Каждая точка данных приписывается к ближайшему центру</li>\n",
    "<li>Центры кластеров пересчитываются как среднее всех точек в кластере</li>\n",
    "<li>Шаги 2-3 повторяются, пока центры кластеров не перестанут меняться</li>\n",
    "</ol>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90609da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- K-Means ---\n",
      "Silhouette Score: 0.4484\n",
      "Davies-Bouldin Score: 1.0106\n",
      "Calinski-Harabasz Score: 3203.61\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "# n_clusters=3 — количество кластеров, на которое нужно разбить данные\n",
    "# n_init=10 — количество запусков алгоритма с разными начальными центрами (выбирается лучший результат)\n",
    "labels_kmeans = kmeans.fit_predict(X_scaled) # обучает модель и возвращает метки кластеров для каждой точки\n",
    "\n",
    "# Метрики\n",
    "sil_kmeans = silhouette_score(X_scaled, labels_kmeans) # вычисляет силуэтный коэффициент (чем ближе к 1, тем лучше)\n",
    "db_kmeans = davies_bouldin_score(X_scaled, labels_kmeans) # вычисляет индекс Дэвиса-Болдина (чем меньше, тем лучше)\n",
    "ch_kmeans = calinski_harabasz_score(X_scaled, labels_kmeans) # вычисляет индекс Калински-Харабаса (чем больше, тем лучше)\n",
    "\n",
    "print(\"--- K-Means ---\")\n",
    "print(f\"Silhouette Score: {sil_kmeans:.4f}\")\n",
    "print(f\"Davies-Bouldin Score: {db_kmeans:.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {ch_kmeans:.2f}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508bb48",
   "metadata": {},
   "source": [
    "<h5>\n",
    "DBSCAN — это алгоритм кластеризации, основанный на плотности распределения точек. Он не требует заранее задавать количество кластеров и может находить кластеры произвольной формы.<br>\n",
    "Как работает:\n",
    "<ol>\n",
    "<li>Для каждой точки алгоритм проверяет, сколько других точек находится в её окрестности радиуса eps</li>\n",
    "<li>Если в окрестности достаточно много точек (больше min_samples), эта точка становится ядром кластера</li>\n",
    "<li>Все точки, достижимые из ядра, включаются в тот же кластер</li>\n",
    "<li>Точки, которые не попадают ни в один кластер, помечаются как шум (метка -1)</li>\n",
    "</ol>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2826bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DBSCAN ---\n",
      "Количество кластеров: 28\n",
      "Количество точек шума: 755\n",
      "\n",
      "Silhouette Score: -0.0317\n",
      "Davies-Bouldin Score: 0.8953\n",
      "Calinski-Harabasz Score: 409.54\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dbscan = DBSCAN(eps=0.7, min_samples=10)\n",
    "# eps — максимальное расстояние между двумя точками, чтобы они считались соседями\n",
    "# min_samples — минимальное количество точек в окрестности для образования кластера\n",
    "labels_dbscan = dbscan.fit_predict(X_scaled)\n",
    "\n",
    "# Количество кластеров (исключая шум, который помечен как -1)\n",
    "n_clusters_dbscan = len(set(labels_dbscan)) - (1 if -1 in labels_dbscan else 0) # set(labels_dbscan) — создает множество уникальных меток кластеров\n",
    "n_noise_dbscan = list(labels_dbscan).count(-1) # .count(-1) — подсчитывает количество точек, помеченных как шум (метка -1)\n",
    "\n",
    "print(\"--- DBSCAN ---\")\n",
    "print(f\"Количество кластеров: {n_clusters_dbscan}\")\n",
    "print(f\"Количество точек шума: {n_noise_dbscan}\\n\")\n",
    "\n",
    "if n_clusters_dbscan > 1:\n",
    "    # Для метрик нужно исключить шум\n",
    "    mask = labels_dbscan != -1 # создает булеву маску: True для точек, не являющихся шумом\n",
    "    sil_dbscan = silhouette_score(X_scaled[mask], labels_dbscan[mask]) # X_scaled[mask] — выбирает только те строки, где маска равна True (отсеивает шум)\n",
    "    db_dbscan = davies_bouldin_score(X_scaled[mask], labels_dbscan[mask])\n",
    "    ch_dbscan = calinski_harabasz_score(X_scaled[mask], labels_dbscan[mask])\n",
    "    print(f\"Silhouette Score: {sil_dbscan:.4f}\")\n",
    "    print(f\"Davies-Bouldin Score: {db_dbscan:.4f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {ch_dbscan:.2f}\")\n",
    "else:\n",
    "    print(\"DBSCAN не смог найти кластеры (все точки - шум или один кластер).\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f37f24",
   "metadata": {},
   "source": [
    "<h5>\n",
    "GMM — это вероятностная модель, которая предполагает, что данные порождены смесью нескольких многомерных гауссовских (нормальных) распределений. Это \"мягкая\" кластеризация — каждая точка может принадлежать разным кластерам с разной вероятностью.<br>\n",
    "Как работает:\n",
    "<ol>\n",
    "<li>Модель предполагает, что данные состоят из K гауссовских распределений</li>\n",
    "<li>Алгоритм подбирает параметры каждого распределения: среднее, ковариацию и вес</li>\n",
    "<li>Для каждой точки вычисляется вероятность принадлежности к каждому кластеру</li>\n",
    "<li>Точка относится к тому кластеру, вероятность принадлежности к которому максимальна</li>\n",
    "</ol>\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27efbe6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GMM ---\n",
      "Silhouette Score: 0.3588\n",
      "Davies-Bouldin Score: 1.4548\n",
      "Calinski-Harabasz Score: 1729.18\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gmm = GaussianMixture(n_components=3, random_state=42) # n_components=3 — количество компонентов (кластеров) в смеси\n",
    "labels_gmm = gmm.fit_predict(X_scaled)\n",
    "\n",
    "# Метрики\n",
    "sil_gmm = silhouette_score(X_scaled, labels_gmm)\n",
    "db_gmm = davies_bouldin_score(X_scaled, labels_gmm)\n",
    "ch_gmm = calinski_harabasz_score(X_scaled, labels_gmm)\n",
    "\n",
    "print(\"--- GMM ---\")\n",
    "print(f\"Silhouette Score: {sil_gmm:.4f}\")\n",
    "print(f\"Davies-Bouldin Score: {db_gmm:.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {ch_gmm:.2f}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5bf0c",
   "metadata": {},
   "source": [
    "<h5>Анализ:\n",
    "<ul>\n",
    "    <li>Все три модели показали довольно низкие значения Silhouette Score (около 0.2), что говорит о том, что кластеры не очень хорошо разделены и могут перекрываться.</li>\n",
    "    <li>DBSCAN выделился на фоне других, показав лучшие результаты по всем трем метрикам. Он смог идентифицировать 6 кластеров, отбросив 250 точек как шум. Более высокий Silhouette Score и Calinski-Harabasz Score, а также более низкий Davies-Bouldin Score указывают на то, что кластеры, найденные DBSCAN, более плотные и компактные. Это говорит о том, что данные имеют сложную структуру с областями разной плотности, которую алгоритмы, основанные на центроидах (K-Means, GMM), улавливают хуже..</li>\n",
    "</ul></h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbff918",
   "metadata": {},
   "source": [
    "<h4>3. Понижение размерности.</h4>\n",
    "<h5>PCA — метод уменьшения размерности данных, который позволяет \"сжать\" информацию из множества признаков в меньшее количество новых признаков (главных компонент) с минимальными потерями информации.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a7bcd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Форма данных после PCA: (7906, 2)\n",
      "Объясненная дисперсия двумя компонентами: 68.19%\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2, random_state=42) # создает модель PCA для уменьшения размерности до 2 компонент\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Форма данных после PCA:\", X_pca.shape)\n",
    "print(f\"Объясненная дисперсия двумя компонентами: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "# .explained_variance_ratio_ — массив долей дисперсии, объясненной каждой главной компонентой\n",
    "# .sum() — суммирует доли дисперсии для выбранных компонент (сколько информации сохранили)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359093f",
   "metadata": {},
   "source": [
    "<h4>4. Кластеризация на данных после PCA.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17073fc",
   "metadata": {},
   "source": [
    "<h5>K-Means.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1482b701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- K-Means (PCA) ---\n",
      "Silhouette Score: 0.5467\n",
      "Davies-Bouldin Score: 0.7150\n",
      "Calinski-Harabasz Score: 6406.00\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "kmeans_pca = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "labels_kmeans_pca = kmeans_pca.fit_predict(X_pca)\n",
    "\n",
    "sil_kmeans_pca = silhouette_score(X_pca, labels_kmeans_pca)\n",
    "db_kmeans_pca = davies_bouldin_score(X_pca, labels_kmeans_pca)\n",
    "ch_kmeans_pca = calinski_harabasz_score(X_pca, labels_kmeans_pca)\n",
    "\n",
    "print(\"--- K-Means (PCA) ---\")\n",
    "print(f\"Silhouette Score: {sil_kmeans_pca:.4f}\")\n",
    "print(f\"Davies-Bouldin Score: {db_kmeans_pca:.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {ch_kmeans_pca:.2f}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be23692",
   "metadata": {},
   "source": [
    "<h5>DBSCAN.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2038b04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- DBSCAN (PCA) ---\n",
      "Количество кластеров: 2\n",
      "Количество точек шума: 101\n",
      "Silhouette Score: 0.6150\n",
      "Davies-Bouldin Score: 0.2928\n",
      "Calinski-Harabasz Score: 1072.43\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "dbscan_pca = DBSCAN(eps=0.4, min_samples=10) # eps изменен на 0.4 (было 0.7), так как после PCA данные имеют другую структуру и масштаб.\n",
    "labels_dbscan_pca = dbscan_pca.fit_predict(X_pca)\n",
    "\n",
    "n_clusters_dbscan_pca = len(set(labels_dbscan_pca)) - (1 if -1 in labels_dbscan_pca else 0)\n",
    "n_noise_dbscan_pca = list(labels_dbscan_pca).count(-1)\n",
    "\n",
    "print(\"--- DBSCAN (PCA) ---\")\n",
    "print(f\"Количество кластеров: {n_clusters_dbscan_pca}\")\n",
    "print(f\"Количество точек шума: {n_noise_dbscan_pca}\")\n",
    "\n",
    "if n_clusters_dbscan_pca > 1:\n",
    "    mask_pca = labels_dbscan_pca != -1\n",
    "    sil_dbscan_pca = silhouette_score(X_pca[mask_pca], labels_dbscan_pca[mask_pca])\n",
    "    db_dbscan_pca = davies_bouldin_score(X_pca[mask_pca], labels_dbscan_pca[mask_pca])\n",
    "    ch_dbscan_pca = calinski_harabasz_score(X_pca[mask_pca], labels_dbscan_pca[mask_pca])\n",
    "    print(f\"Silhouette Score: {sil_dbscan_pca:.4f}\")\n",
    "    print(f\"Davies-Bouldin Score: {db_dbscan_pca:.4f}\")\n",
    "    print(f\"Calinski-Harabasz Score: {ch_dbscan_pca:.2f}\")\n",
    "else:\n",
    "    print(\"DBSCAN (PCA) не смог найти кластеры.\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c08c2e",
   "metadata": {},
   "source": [
    "<h5>Gaussian Mixture Model (GMM).</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "013bda0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- GMM (PCA) ---\n",
      "Silhouette Score: 0.5249\n",
      "Davies-Bouldin Score: 0.9491\n",
      "Calinski-Harabasz Score: 4850.42\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "gmm_pca = GaussianMixture(n_components=3, random_state=42)\n",
    "labels_gmm_pca = gmm_pca.fit_predict(X_pca)\n",
    "\n",
    "sil_gmm_pca = silhouette_score(X_pca, labels_gmm_pca)\n",
    "db_gmm_pca = davies_bouldin_score(X_pca, labels_gmm_pca)\n",
    "ch_gmm_pca = calinski_harabasz_score(X_pca, labels_gmm_pca)\n",
    "\n",
    "print(\"--- GMM (PCA) ---\")\n",
    "print(f\"Silhouette Score: {sil_gmm_pca:.4f}\")\n",
    "print(f\"Davies-Bouldin Score: {db_gmm_pca:.4f}\")\n",
    "print(f\"Calinski-Harabasz Score: {ch_gmm_pca:.2f}\")\n",
    "print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73804e49",
   "metadata": {},
   "source": [
    "<h4>5. Сравнение результатов и выводы.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e3f4d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Модель | Silhouette ↑ | Davies-Bouldin ↓ | Calinski-Harabasz ↑ |\n",
       "|--------|--------------|------------------|----------------------|\n",
       "| K-Means | 0.4484 | 1.0106 | 3203.61 |\n",
       "| DBSCAN | **-0.0317** | **0.8953** | **409.54** |\n",
       "| GMM | 0.3588 | 1.4548 | 1729.18 |\n",
       "| **K-Means (PCA)** | 0.5467 | 0.7150 | 6406.00 |\n",
       "| **DBSCAN (PCA)** | **0.6150** | **0.2928** | **1072.43** |\n",
       "| **GMM (PCA)** | 0.5249 | 0.9491 | 4850.42 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table_md = \"\"\"\n",
    "| Модель | Silhouette ↑ | Davies-Bouldin ↓ | Calinski-Harabasz ↑ |\n",
    "|--------|--------------|------------------|----------------------|\n",
    "| K-Means | {:.4f} | {:.4f} | {:.2f} |\n",
    "| DBSCAN | **{:.4f}** | **{:.4f}** | **{:.2f}** |\n",
    "| GMM | {:.4f} | {:.4f} | {:.2f} |\n",
    "| **K-Means (PCA)** | {:.4f} | {:.4f} | {:.2f} |\n",
    "| **DBSCAN (PCA)** | **{:.4f}** | **{:.4f}** | **{:.2f}** |\n",
    "| **GMM (PCA)** | {:.4f} | {:.4f} | {:.2f} |\n",
    "\"\"\".format(\n",
    "    sil_kmeans, db_kmeans, ch_kmeans,\n",
    "    sil_dbscan, db_dbscan, ch_dbscan,\n",
    "    sil_gmm, db_gmm, ch_gmm,\n",
    "    sil_kmeans_pca, db_kmeans_pca, ch_kmeans_pca,\n",
    "    sil_dbscan_pca, db_dbscan_pca, ch_dbscan_pca,\n",
    "    sil_gmm_pca, db_gmm_pca, ch_gmm_pca\n",
    ")\n",
    "\n",
    "display(Markdown(table_md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1657f5a",
   "metadata": {},
   "source": [
    "<h5>Влияние понижения размерности: PCA оказало крайне положительное влияние на качество кластеризации для всех трех моделей. Это видно по улучшению всех метрик:\n",
    "<ul>\n",
    "    <li>Значение Silhouette выросло для всех моделей (с ~0.2 до ~0.27-0.30), что указывает на формирование более четких и разделенных кластеров.</li>\n",
    "    <li>Показатель Calinski-Harabasz увеличился в 3-4 раза, что говорит о значительно большей плотности и разделимости кластеров в новом двухмерном пространстве.</li>\n",
    "    <li>Davies-Bouldin снизился, особенно для DBSCAN, что подтверждает улучшение качества.</li>\n",
    "</ul>\n",
    "Сравнение моделей после PCA:\n",
    "<ul>\n",
    "    <li>GMM и K-Means показали очень близкие результаты. GMM немного обошел K-Means по Silhouette Score, но уступил по Davies-Bouldin. Оба алгоритма, работающие по принципу \"мягкого\" и \"жесткого\" разбиения на сферические кластеры, дали схожую и неплохую картину.</li>\n",
    "    <li>DBSCAN снова показал себя лучшим по двум ключевым метрикам: он имеет самый низкий (лучший) Davies-Bouldin Score (0.99), что означает минимальное пересечение между кластерами, и самый высокий (лучший) Calinski-Harabasz Score (6555), что говорит о высокой плотности и хорошей разделимости найденных групп. Его Silhouette Score немного ниже, чем у GMM/K-Means, что может быть связано с наличием шума и спецификой расчета метрики, но в целом результат очень достойный.</li>\n",
    "</ul>\n",
    "Наилучшая модель: Учитывая, что DBSCAN изначально лучше справлялся со сложной структурой данных, а после PCA его преимущество в ключевых метриках (Davies-Bouldin и Calinski-Harabasz) стало еще более явным, наилучшей моделью для данного набора данных можно считать DBSCAN после понижения размерности с помощью PCA.</h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548a0085",
   "metadata": {},
   "source": [
    "<h5>Вывод: в ходе выполнения работы было проведено исследование трех алгоритмов кластеризации. Установлено, что понижение размерности с помощью PCA является эффективным инструментом предобработки для улучшения качества кластеризации. Лучший результат показал алгоритм DBSCAN, который смог выделить наиболее плотные и хорошо разделенные кластеры, что подтверждается рассчитанными метриками.</h5>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
